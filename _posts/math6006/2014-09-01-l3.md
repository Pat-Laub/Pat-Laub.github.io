---
layout: post
title: Cross-entropy example
subtitle: Minimising Rastrigin’s function
category: math6006 
tags: [math, monte carlo]
author: pjl
excerpt: >
    Consider minimising the test function – named Rastrigin’s function –
    defined by

    $$S({\boldsymbol{x}}) = 20 + x_1^2 + x_2^2 - 10\cos(2\pi x_1) - 10\cos(2\pi x_2).$$

    One cross-entropy approach could be as follows.
---
Problem
=======

Consider minimising the test function – named Rastrigin’s function –
defined by

$$S({\boldsymbol{x}}) = 20 + x_1^2 + x_2^2 - 10\cos(2\pi x_1) - 10\cos(2\pi x_2).$$

This is how it looks:
![image]({{ site.url }}/images/math6006/rastrigin.png){: .image .featured}

One cross-entropy approach could be as follows.


Formulation
===========

State that

$$S({\boldsymbol{x}}^*) = \gamma^* = \max_{ {\boldsymbol{x}}\in {\mathbb{R}}^2} S({\boldsymbol{x}}).$$

Consider a family of pdfs
$\\{ f(\cdot\,; {\boldsymbol{v}}) : v \in \mathcal{V} \\}$ on
${\mathbb{R}}^2$. We will construct a sequence of pdfs

$$(f(\cdot\,; {\boldsymbol{u}}), f(\cdot\,; {\boldsymbol{v}}_1), f(\cdot\,; {\boldsymbol{v}}_2), \dots, f(\cdot\,; {\boldsymbol{v}}_N))$$

which start with parameter ${\boldsymbol{u}}={\boldsymbol{v}}_0$ and aim
to converge on the zero-variance distribution whose mass is on the point
${\boldsymbol{x}}^*$. In order to do this, we need to be able to solve
the program:

$${\boldsymbol{v}}_t = \underset{ {\boldsymbol{v}}}{\arg\max} \, \frac{1}{N} \sum_{i=1}^N I_{\\{S({\boldsymbol{X}}_i) \geq \hat{\gamma}_t\\}} \ln f({\boldsymbol{X}}_i; {\boldsymbol{v}})$$

where the
$\{ {\boldsymbol{X}}_i \} {\overset{iid}{\sim}}f(\cdot\,; {\boldsymbol{v}}_{t-1})$.
Though this is simpler when ${\boldsymbol{v}}_t$ is viewed as the
maximum likelihood estimates (MLEs) of $\\{ {\boldsymbol{X}}_i \\}$, which
is known analytically for many distributions.\
In this case we’ve chosen $f$ to be of family of bivariate normal
distributions, i.e.

$$f({\boldsymbol{x}}; {\boldsymbol{v}}_i) = f({\boldsymbol{x}}; ({\boldsymbol{\mu}}_i, \Sigma_i)) = (2\pi)^{-1} \Sigma_i^{-1/2} \exp \left\\{-\frac{1}{2} ({\boldsymbol{x}}-{\boldsymbol{\mu}}_i)^t \Sigma_i^{-1} ({\boldsymbol{x}}-{\boldsymbol{\mu}}_i) \right\\}.$$

The MLEs for ${\boldsymbol{\mu}}_i$ and $\Sigma_i$ given some data
$\\{ {\boldsymbol{X}}_i\\}$ is simply the sample mean and the sample
covariance matrix respectively.

Implementation
==============

![image]({{ site.url }}/images/math6006/progress.jpg){: .center-image}
![image]({{ site.url }}/images/math6006/logprogress.jpg){: .center-image}
![image]({{ site.url }}/images/math6006/rast1.jpg){: .center-image}
![image]({{ site.url }}/images/math6006/rastImpDens1.jpg){: .center-image}
![image]({{ site.url }}/images/math6006/rast2.jpg){: .center-image}
![image]({{ site.url }}/images/math6006/rastImpDens2.jpg){: .center-image}
![image]({{ site.url }}/images/math6006/rast3.jpg){: .center-image}
![image]({{ site.url }}/images/math6006/rastImpDens3.jpg){: .center-image}
![image]({{ site.url }}/images/math6006/rast4.jpg){: .center-image}
![image]({{ site.url }}/images/math6006/rastImpDens4.jpg){: .center-image}
![image]({{ site.url }}/images/math6006/rast5.jpg){: .center-image}
![image]({{ site.url }}/images/math6006/rastImpDens5.jpg){: .center-image}
![image]({{ site.url }}/images/math6006/rast7.jpg){: .center-image}
![image]({{ site.url }}/images/math6006/rastImpDens7.jpg){: .center-image}
![image]({{ site.url }}/images/math6006/rast10.jpg){: .center-image}
![image]({{ site.url }}/images/math6006/rastImpDens10.jpg){: .center-image}
![image]({{ site.url }}/images/math6006/rast15.jpg){: .center-image}
![image]({{ site.url }}/images/math6006/rastImpDens15.jpg){: .center-image}
![image]({{ site.url }}/images/math6006/rast20.jpg){: .center-image}
![image]({{ site.url }}/images/math6006/rastImpDens20.jpg){: .center-image}
![image]({{ site.url }}/images/math6006/rast21.jpg){: .center-image}
![image]({{ site.url }}/images/math6006/rastImpDens21.jpg){: .center-image}
![image]({{ site.url }}/images/math6006/rast22.jpg){: .center-image}
![image]({{ site.url }}/images/math6006/rastImpDens22.jpg){: .center-image}
![image]({{ site.url }}/images/math6006/rast26.jpg){: .center-image}
![image]({{ site.url }}/images/math6006/rastImpDens26.jpg){: .center-image}

Program output:

    Minimum: 566.6  mu: (100,100)   sum(sigma): 1e+04
    Minimum: 105.6  mu: (38.19,23.61)   sum(sigma): 2947
    Minimum: 17.88  mu: (17.86,1.62)    sum(sigma): 628
    Minimum: 8.878  mu: (4.078,0.9193)  sum(sigma): 79.88
    Minimum: 3.927  mu: (1.031,0.1458)  sum(sigma): 5.894
    Minimum: 2.804  mu: (0.366,-0.07075)    sum(sigma): 2.539
    Minimum: 2.621  mu: (0.3736,-0.2191)    sum(sigma): 2.696
    Minimum: 3.371  mu: (0.4345,0.05753)    sum(sigma): 2.68
    Minimum: 2.248  mu: (-0.1047,-0.09262)  sum(sigma): 2.998
    Minimum: 1.492  mu: (-0.2859,0.1824)    sum(sigma): 1.594
    Minimum: 1.587  mu: (-0.3357,0.1226)    sum(sigma): 0.8068
    Minimum: 0.7777 mu: (-0.2582,0.1078)    sum(sigma): 0.8715
    Minimum: 0.2609 mu: (-0.3372,-0.1298)   sum(sigma): 0.6092
    Minimum: 0.4489 mu: (-0.3467,0.01045)   sum(sigma): 0.8966
    Minimum: 1.491  mu: (-0.1771,0.1859)    sum(sigma): 1.005
    Minimum: 0.469  mu: (-0.04962,0.3966)   sum(sigma): 1.375
    Minimum: 1.251  mu: (-0.05884,0.2697)   sum(sigma): 1.046
    Minimum: 1.53   mu: (-0.2133,0.006174)  sum(sigma): 1.104
    Minimum: 1.082  mu: (-0.1391,-0.1123)   sum(sigma): 0.99
    Minimum: 0.2011 mu: (-0.04912,-0.006557)    sum(sigma): 0.6049
    Minimum: 0.1566 mu: (-0.05435,0.002617) sum(sigma): 0.1822
    Minimum: 0.0002754  mu: (-0.02384,0.0008551)    sum(sigma): 0.004705
    Minimum: 0.002779   mu: (-0.005473,-0.003327)   sum(sigma): 0.0003641
    Minimum: 5.379e-05  mu: (0.0002474,5.669e-05)   sum(sigma): 7.661e-05
    Minimum: 9.127e-05  mu: (-0.0003505,-7.848e-05) sum(sigma): 1.049e-05
    Minimum: 1.624e-07  mu: (6.175e-05,0.0002736)   sum(sigma): 1.791e-06
    Minimum: 5.834e-08  mu: (-2.88e-05,0.0001088)   sum(sigma): 9.217e-08
    Converged after 27 iterations.
