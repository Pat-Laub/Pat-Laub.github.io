<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.7">Jekyll</generator><link href="https://pat-laub.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://pat-laub.github.io/" rel="alternate" type="text/html" /><updated>2023-09-04T05:05:01+00:00</updated><id>https://pat-laub.github.io/feed.xml</id><title type="html">Patrick Laub</title><subtitle>Maths and programming etc.
    </subtitle><entry><title type="html">Hunting for a Bluey episode with AI</title><link href="https://pat-laub.github.io/2022/02/08/hunting-for-great-bluey-episodes-with-ai.html" rel="alternate" type="text/html" title="Hunting for a Bluey episode with AI" /><published>2022-02-08T00:00:00+00:00</published><updated>2022-02-08T00:00:00+00:00</updated><id>https://pat-laub.github.io/2022/02/08/hunting-for-great-bluey-episodes-with-ai</id><content type="html" xml:base="https://pat-laub.github.io/2022/02/08/hunting-for-great-bluey-episodes-with-ai.html">&lt;h2 id=&quot;problem&quot;&gt;Problem&lt;/h2&gt;
        &lt;p&gt;I’ve been enjoying listening to the &lt;a href=&quot;https://syntax.fm&quot;&gt;Syntax Web Development&lt;/a&gt; podcast in the last few months, and I was very surprised that in one episode the hosts went way off-track to recommended a great &lt;a href=&quot;https://www.imdb.com/title/tt7678620/&quot;&gt;Bluey&lt;/a&gt; episode. Bluey is a phenomenal kids show, and it’s even based in the part of Australia that I used to lived in (Brisbane, Queensland) so I enjoy all the background references to Brisbane that pop up in the show.&lt;/p&gt;
        &lt;p&gt;About a month after the podcast episode, I decided to watch that recommended Bluey episode.
        But I couldn’t remember which Bluey episode was recommended, nor could I remember which Syntax episode the hosts went on this tangent about children’s TV.
        The podcast releases new episodes at a furious rate, and the episodes go for about 30 mins to an hour.
        I couldn’t find any transcripts of the episodes provided by the hosts, and after a few days of intermittently re-listening to old episodes to find that section, I gave up.&lt;/p&gt;
        &lt;p&gt;As I’m teaching deep-learning later in the year, I thought I’d use this as an example of using Python &amp;amp; machine learning to side-step a long and tedious manual search for this information.&lt;/p&gt;
        &lt;h2 id=&quot;downloading-the-podcast-episodes&quot;&gt;Downloading the podcast episodes&lt;/h2&gt;
        &lt;p&gt;Python has a package for everything, so my first reaction was to Google “Python package to download podcast episodes”, and this returned a bunch of libraries focusing on this specific task.
        However, none of them worked as intended.
        After testing a few different packages, and variously getting some kind of HTTP or file-system errors, I gave up on this approach (I think either the packages were tested on Mac while I am currently stuck on Windows, or my anti-virus was intercepting the requests).&lt;/p&gt;
        &lt;p&gt;Eventually, I remembered that podcasts are just defined as RSS feeds, which are just text files which have links to where to find each episode as an MP3.
        So, I just opened up the podcast homepage and found the &lt;a href=&quot;http://feed.syntax.fm/rss&quot;&gt;RSS link&lt;/a&gt; and searched for “.mp3” to manually download the last few episodes.&lt;/p&gt;
        &lt;p&gt;For example, here is a chunk of the RSS file:&lt;/p&gt;
        &lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;enclosure&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;length=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;58157223&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;type=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;audio/mpeg&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;url=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;https://traffic.libsyn.com/secure/syntax/Syntax_-_428.mp3?dest-id=532671&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;itunes:duration&amp;gt;&lt;/span&gt;01:00:31&lt;span class=&quot;nt&quot;&gt;&amp;lt;/itunes:duration&amp;gt;&lt;/span&gt;
        ...
        &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
        &lt;h2 id=&quot;trying-various-free-speech-to-text-solutions&quot;&gt;Trying various free Speech-To-Text solutions&lt;/h2&gt;
        &lt;h3 id=&quot;got-some-rough-transcript-using-mozillas-deepspeech&quot;&gt;Got some rough transcript using Mozilla’s DeepSpeech&lt;/h3&gt;
        &lt;p&gt;In the past I used &lt;a href=&quot;https://deepspeech.readthedocs.io/en/r0.9/?badge=latest&quot;&gt;Mozilla’s DeepSpeech&lt;/a&gt; software to convert speech to text for free.
        This is a pre-trained neural network model which can process the podcast audio files and generate transcripts for the episodes.
        I didn’t want to run the conversion on my local computer, so I found an &lt;a href=&quot;https://colab.research.google.com/github/tugstugi/dl-colab-notebooks/blob/master/notebooks/MozillaDeepSpeech.ipynb&quot;&gt;example Jupyter Notebook on Google Colab&lt;/a&gt; which did something similar (it transcribed YouTube videos with DeepSpeech) and adapted it.&lt;/p&gt;
        &lt;p&gt;After a few quick adjustments to the example notebook (using ‘!wget &amp;lt;url/to/podcast&amp;gt;.mp3’ instead of the YouTube video downloading, and updating the DeepSpeech version numbers to the latest pre-trained models) I could get some automatically generated transcripts.&lt;/p&gt;
        &lt;p&gt;However the output was so error-prone rate that is was mostly garbage.
        For example, episode 428 starts with (here I am transcribing manually):&lt;/p&gt;
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;You're listening to Syntax, the podcast with the tastiest web development treats out there. Strap yourself in and get ready, here is Scott Tolinski and Wes Bos.
        &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
        &lt;p&gt;whereas the auto-generated transcript for this introduction was:&lt;/p&gt;
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;resorting to santa bianca with its tastes we toiletries out there strap yourself in and get ready personality and west boss egadean as ...
        &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
        &lt;p&gt;Admittedly, this introduction is played over the top of some music and in an unusual delivery, so I wouldn’t expect too much for this section.
        And later, for the technical discussions about JavaScript and TypeScript etc., I hadn’t expected a generic speech-to-text method to work well on those parts of the episodes.&lt;/p&gt;
        &lt;h3 id=&quot;looking-for-nearly-perfect-transcripts-a-la-youtubes-auto-captions&quot;&gt;Looking for nearly-perfect transcripts, a la YouTube’s auto-captions&lt;/h3&gt;
        &lt;p&gt;When recording lectures for my students in 2020, I found that YouTube’s auto-captioning worked miracles.
        I would simply upload my lecture recording to YouTube, wait until their machines got around to auto-generating the captions (usually within a few hours), download the AI transcripts and adjust the infrequent error if needed.
        The DeepSpeech output was nowhere near the level of accuracy that YouTube could do.&lt;/p&gt;
        &lt;p&gt;Presumably, YouTube was running &lt;a href=&quot;https://cloud.google.com/speech-to-text/&quot;&gt;Google’s Speech API&lt;/a&gt; in the background.
        As Google (and the comparable offers from Microsoft and Amazon) only allowed a relatively short amount of audio to be transcribed for free as part of a trial period, I couldn’t use this to solve my podcast problem.&lt;/p&gt;
        &lt;p&gt;I did use &lt;a href=&quot;https://www.ffmpeg.org/&quot;&gt;ffmpeg&lt;/a&gt; to turn one of the podcast episodes from an audio file to a video file, which I uploaded to YouTube (as a private video, now deleted) in order to &lt;a href=&quot;https://support.google.com/youtube/answer/2734705?hl=en#&quot;&gt;download the auto-captions&lt;/a&gt;; this created one transcript with almost no errors.
        For example, the subtitle file (in the ‘.srt’ file format) for episode 427 starts with:&lt;/p&gt;
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1
        00:00:01,120 --&amp;gt; 00:00:07,120
        monday monday monday open wide dev fans
        2
        00:00:04,720 --&amp;gt; 00:00:09,519
        get ready to stuff your face with
        3
        00:00:07,120 --&amp;gt; 00:00:11,679
        javascript css node modules barbecue
        4
        00:00:09,519 --&amp;gt; 00:00:14,080
        tips get workflows break dancing soft
        5
        00:00:11,679 --&amp;gt; 00:00:16,800
        skills web development the hastiest the
        6
        00:00:14,080 --&amp;gt; 00:00:19,680
        craziest the tastiest web development
        7
        00:00:16,800 --&amp;gt; 00:00:24,240
        treats coming in hot here is wes
        &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
        &lt;p&gt;Even though this worked very well, I dared not repeat this process for the month’s worth of podcasts in case YouTube banned me for breaking some terms of service (or in case the Syntax guys sued me or something).
        In any case, it wouldn’t be a great example of utilising deep learning for my future students.
        While converting the audio to video, I did try the auto-captioning available in &lt;a href=&quot;https://www.techsmith.com/video-editor.html&quot;&gt;Camtasia&lt;/a&gt; (since I just coincidentally installed the software). This generated garbage outputs, potentially worse than Deep Speech.&lt;/p&gt;
        &lt;h3 id=&quot;taking-another-go-at-deepspeech&quot;&gt;Taking another go at DeepSpeech&lt;/h3&gt;
        &lt;p&gt;Upon returning to DeepSpeech, I thought that the obvious next step would be to &lt;em&gt;fine-tune&lt;/em&gt; the model so that it would become great at recognising just the voices of the two hosts on the Syntax podcast.
        The DeepSpeech documentation has &lt;a href=&quot;https://deepspeech.readthedocs.io/en/v0.9.3/TRAINING.html#fine-tuning-same-alphabet&quot;&gt;a guide to fine-tuning&lt;/a&gt; the speech models.
        So I manually transcribed the first few minutes of the latest Syntax episode, with the idea of feeding in the audio &amp;amp; transcript to the fine-tuning process.
        However, I found this really great &lt;a href=&quot;https://discourse.mozilla.org/t/fine-tuning-with-limited-data-questions-on-fine-tuning-in-general/68014&quot;&gt;discussion about fine-tuning with a small dataset&lt;/a&gt; and basically abandoned this direction; I didn’t have the patience to produce hours of transcripts that appeared necessary for this approach to pay-off.
        Other parts of the Mozilla forums did mention that &lt;a href=&quot;https://stt.readthedocs.io/en/latest/index.html&quot;&gt;Coqui STT&lt;/a&gt; may be a better alternative to DeepSpeech, though I didn’t want to give up on it just yet.&lt;/p&gt;
        &lt;p&gt;Looking around the Mozilla forums a bit more gave me an important insight.
        I didn’t need a speech model that recognised &lt;em&gt;every word&lt;/em&gt; the podcasts hosts spoke, but in fact I just needed something that would find the word “Bluey” in a long audio file.
        Alexa, Cortana, and Siri act in exactly this way.
        They are always listening to us, but normally they are just listening for their specific &lt;em&gt;wake words&lt;/em&gt; like “Hey Siri, …” or “Alexa, …”.
        If I could add “Bluey” as a kind of wake-word, I’d be set, and the newest DeepSpeech versions have a similar concept called &lt;a href=&quot;https://deepspeech.readthedocs.io/en/master/HotWordBoosting-Examples.html&quot;&gt;hot word boosting&lt;/a&gt; which appears to make the model more sensitive to picking up specific words.&lt;/p&gt;
        &lt;p&gt;After all of this reading and mucking around, I thought I better just try the obvious thing first, and just run the unaltered/vanilla DeepSpeech on the last month’s worth of podcasts and check that “Bluey” didn’t already appear in the mostly gibberish auto-generated transcripts.
        Here is the &lt;a href=&quot;/notebooks/Using_DeepSpeech_on_Podcasts.ipynb&quot;&gt;Jupyter Notebook&lt;/a&gt; I wrote to run this process.&lt;/p&gt;
        &lt;p&gt;From the example Jupyter notebook I was really happy/shocked to find that the Jupyter exclamation mark syntax, which is used to call Linux command-line programs, could be integrated into Python code.
        So to download and transcribe the latest batch of episodes, I could simply run:&lt;/p&gt;
        &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;episodeNumber&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;427&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;406&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;podName&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;f&quot;Syntax_-_&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;episodeNumber&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exists&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;podName&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;.mp3&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;f&quot;https://traffic.libsyn.com/secure/syntax/&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;podName&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;.mp3&quot;&lt;/span&gt;
        &lt;span class=&quot;err&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wget&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;err&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ffmpeg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;podName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mp3&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;podName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wav&lt;/span&gt;
        &lt;span class=&quot;err&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;deepspeech&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;deepspeech&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pbmm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scorer&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;deepspeech&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scorer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;audio&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;podName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wav&lt;/span&gt;
        &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
        &lt;p&gt;I left Google Colab to feed the recent podcast episodes into DeepSpeech in reverse order, and after I returned from lunch I found Colab had kicked me off due to inactivity, but beforehand it had processed 14 episodes:&lt;/p&gt;
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Inference took 366.552s for 1359.543s audio file.
        Inference took 1305.095s for 3634.286s audio file.
        Inference took 276.029s for 1119.660s audio file.
        Inference took 449.628s for 1574.165s audio file.
        Inference took 1329.048s for 3324.264s audio file.
        Inference took 34.462s for 164.963s audio file.
        Inference took 344.598s for 1372.630s audio file.
        Inference took 82.053s for 24347.887s audio file.
        Inference took 468.245s for 1808.327s audio file.
        Inference took 1119.990s for 3788.669s audio file.
        Inference took 272.974s for 1148.056s audio file.
        Inference took 1129.176s for 3481.417s audio file.
        Inference took 532.887s for 1995.677s audio file.
        Inference took 1180.540s for 3843.344s audio file.
        &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
        &lt;p&gt;Searching for “blue” in the sludge of error-filled text that was generated, I did find&lt;/p&gt;
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;... like one example is bluely or kissed favours the world is blue and bethabara characters is a buoy oh i intoshes know that my kids go bananas for it mykenai's very cute were ...
        &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
        &lt;p&gt;towards the end of episode 417. After re-listening to that part of the episode, I found this is exactly what I was looking for!
        It was the &lt;a href=&quot;https://blueypedia.fandom.com/wiki/Flat_Pack&quot;&gt;Flat Pack episode&lt;/a&gt; that was recommended (S2E24).
        Now that I just watched it, I agree it was quite a good episode!
        It should have been a ‘sick pick’ haha.&lt;/p&gt;
        &lt;h2 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h2&gt;
        &lt;p&gt;What did I learn from this experience?&lt;/p&gt;
        &lt;ul&gt;
        &lt;li&gt;I need to remember to solve the simplest version of the problem (here I needed to find the word “Bluey”, not get perfect transcripts for the episodes).&lt;/li&gt;
        &lt;li&gt;That we get used to great machine-learning algorithms, like the YouTube automatic captioning system, and forget that problems like speech-to-text are &lt;em&gt;really hard&lt;/em&gt; to solve.&lt;/li&gt;
        &lt;li&gt;I should be skeptical of small Python packages which are just dumped on the Python package index.&lt;/li&gt;
        &lt;li&gt;That the automated/AI solution can be slower than the manual version (here, I certainly could have re-listened to a month’s worth of podcasts faster than solving this problem with software; heck, I probably could have watched all of Bluey in this time!).&lt;/li&gt;
        &lt;/ul&gt;
        &lt;p&gt;&lt;img src=&quot;/images/bluey-swing-chair.png&quot; alt=&quot;image&quot; class=&quot;image post_image&quot; /&gt;&lt;/p&gt;</content><author><name>pjl</name></author><category term="code" /><summary type="html">I've been listening to the Syntax podcast for the last few months, and I was very surprised that in one episode they recommended a great Bluey episode. Though I forgot which episode contained the recommendation. As I'm teaching deep-learning later in the year, I thought I'd use this as an example of using Python &amp; ML to side-step a long and tedious manual search for it.</summary></entry><entry><title type="html">The Elements of Hawkes Processes</title><link href="https://pat-laub.github.io/2022/01/25/elements-of-hawkes-processes.html" rel="alternate" type="text/html" title="The Elements of Hawkes Processes" /><published>2022-01-25T00:00:00+00:00</published><updated>2022-01-25T00:00:00+00:00</updated><id>https://pat-laub.github.io/2022/01/25/elements-of-hawkes-processes</id><content type="html" xml:base="https://pat-laub.github.io/2022/01/25/elements-of-hawkes-processes.html">&lt;p&gt;Our book has now been published! 
        It is now available on &lt;a href=&quot;https://link.springer.com/book/10.1007/978-3-030-84639-8&quot;&gt;Springer Link&lt;/a&gt;.
        Check it out.&lt;/p&gt;</content><author><name>pjl</name></author><category term="math" /><category term="code" /><category term="books" /><summary type="html">Our book has now been published! It is now available on Springer Link. Check it out.</summary></entry><entry><title type="html">Chaos theory meets C++</title><link href="https://pat-laub.github.io/2021/05/14/edm-and-code-review.html" rel="alternate" type="text/html" title="Chaos theory meets C++" /><published>2021-05-14T00:00:00+00:00</published><updated>2021-05-14T00:00:00+00:00</updated><id>https://pat-laub.github.io/2021/05/14/edm-and-code-review</id><content type="html" xml:base="https://pat-laub.github.io/2021/05/14/edm-and-code-review.html">&lt;p&gt;Since starting at Uni Melbourne, I’ve been working on a plugin for Stata which implements &lt;a href=&quot;https://jinjingli.github.io/edm&quot;&gt;Empirical Dynamic Modelling&lt;/a&gt;, a stats tool with the funnily misleading acronym EDM.
        Have you ever heard the line “correlation does not equal causation”?
        Well EDM aims to fix that.
        It looks at data and can actually determine that some $X$ thing is causally influencing some other thing $Y$ in a potentially nonlinear &amp;amp; complicated way.
        There are some pretty nice Youtube videos outlining the method:&lt;/p&gt;
        &lt;p&gt;
        &lt;iframe width=&quot;560&quot; height=&quot;315&quot; class=&quot;image&quot; src=&quot;https://www.youtube.com/embed/fevurdpiRYg&quot; title=&quot;YouTube video player&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
        &lt;/p&gt;
        &lt;p&gt;
        &lt;iframe width=&quot;560&quot; height=&quot;315&quot; class=&quot;image&quot; src=&quot;https://www.youtube.com/embed/NrFdIz-D2yM&quot; title=&quot;YouTube video player&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
        &lt;/p&gt;
        &lt;p&gt;
        &lt;iframe width=&quot;560&quot; height=&quot;315&quot; class=&quot;image&quot; src=&quot;https://www.youtube.com/embed/QQwtrWBwxQg&quot; title=&quot;YouTube video player&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
        &lt;/p&gt;
        &lt;p&gt;The opportunities created with such a tool are pretty impressive.
        In the &lt;a href=&quot;https://jinjingli.github.io/edm/edm-wp.pdf&quot;&gt;Stata journal paper&lt;/a&gt; we wrote, there’s an example linking the effect of the weather on the amount of crime.
        Also, we have quite a lot of data on people’s emotions measured over a few weeks or so (participants answered a survey which popped up on their phone frequently).
        We’re going to try to analyse this, to look at what’s causing a person’s mood to change, and how one might nudge them into a better/happier mental state.
        This gif shows some of this data animated; it plots some combination of overall postive feelings on the $x$ axis (PA = “positive affect”) and some summary of the negative feelings on the $y$ axis for some person over time.
        It’s quite hypnotising to watch these animations; some of them show really bimodal distributions, which may possibly be a manifestation of bipolar disorder.&lt;/p&gt;
        &lt;p&gt;&lt;img src=&quot;/images/emotions.gif&quot; alt=&quot;image&quot; class=&quot;image post_image&quot; /&gt;&lt;/p&gt;
        &lt;p&gt;The plugin’s &lt;a href=&quot;https://edm-developers.github.io/EDM/&quot;&gt;homepage&lt;/a&gt; hosts installation instructions &amp;amp; some documentation.
        While our Stata Journal paper really goes into detail about the method, there’s another paper &lt;a href=&quot;https://www.researchgate.net/publication/317339714_Empirical_dynamic_modeling_for_beginners&quot;&gt;EDM for beginners&lt;/a&gt; which is also a good place to start.&lt;/p&gt;
        &lt;p&gt;If you’re a software developer, I’d be interested in hearing any feedback or suggestions for this codebase!
        The plugin is written in C++, and was recently made public on &lt;a href=&quot;https://github.com/EDM-Developers/EDM&quot;&gt;Github&lt;/a&gt;.&lt;/p&gt;
        &lt;p&gt;To describe the computational side of EDM, I’ll butcher this beautiful theory (it is based on chaos theory &amp;amp; geometry, things I don’t fully understand myself) to give you a basic programmer-friendly overview. Say we have some data measured every day, e.g. daily temperature, or the number of crimes committed each day. EDM takes this raw data, which let’s say looks like&lt;/p&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;[1, 2, 3, 4, 5, 6]&lt;/script&gt;
        &lt;p&gt;and breaks it into little overlapping chunks using a rolling window, for example&lt;/p&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
        \begin{align*}
        &amp;[1,2,3], \\
        &amp;[2,3,4], \\
        &amp;[3,4,5], \\
        &amp;[4,5,6].
        \end{align*} %]]&gt;&lt;/script&gt;
        &lt;p&gt;This collection is call the time-delayed or reconstructed manifold.
        The main computational part of EDM is to calculate the nearest neighbours between combination of rows in this manifold, i.e. between each of these mini-trajectories.
        Sometimes, after finding the neighbours, we throw these into a matrix and solve a classic $A \mathbf{x} = \mathbf{b}$ linear system of equations (using SVD), but most of the time this is quite fast compared to the nearest neighbour search.&lt;/p&gt;
        &lt;p&gt;The plugin is working well, and the performance is pretty good since it is multi-threaded. The plugin is a dynamically linked library, and Stata provides us a crude C API to read data from &amp;amp; save data to itself.&lt;/p&gt;
        &lt;p&gt;We support Mac OS, Windows, and Linux (tested on Ubuntu) on x86 and also ARM on Mac. So when Stata installs the plugin, it downloads 3 binaries for Mac (a universal binary), Windows &amp;amp; Linux, and loads the correct one given the current OS. If, for any reason, these binaries can’t load, then there’s a pure-Stata backup implementation which will kick in; this is much slower and it is only single-threaded.&lt;/p&gt;
        &lt;p&gt;This setup, and some of our own UX goals, provides some difficult restrictions on the codebase:&lt;/p&gt;
        &lt;ul&gt;
        &lt;li&gt;any change to the C++ output must exactly match the pure-Stata backup implementation,&lt;/li&gt;
        &lt;li&gt;crashes like segfaults are particularly terrible, since our code runs inside the original Stata process, so a crash will wipe out any data and results inside the current Stata process,&lt;/li&gt;
        &lt;li&gt;we stick to header-only libraries for our dependencies; if we relied on dynamically-loaded dependencies then we’d have to distribute a huge bunch of DLLs for each OS &amp;amp; instruction set &amp;amp; etc; also, the build process of Apple Universal Binaries is significantly harder with DLL dependencies,&lt;/li&gt;
        &lt;li&gt;we try not to have any dependencies at all for the user; e.g. we don’t want to force users of the package to go install the Visual Studio C runtime, or tell them to open a terminal and run “brew install libomp” something or other,&lt;/li&gt;
        &lt;li&gt;we want the Stata interface to not freeze while the calculations progress, and to see some visual indication of the progress inside Stata,&lt;/li&gt;
        &lt;li&gt;we want the main compilers, clang, gcc &amp;amp; msvc, to all handle the code without issues.&lt;/li&gt;
        &lt;/ul&gt;
        &lt;p&gt;This leads to some compromises in the code which I fear is a bit ugly. For example, to add multi-threading I would have hoped to just use OpenMP. We’re sharing a process with Stata and Stata itself has loaded a version of OpenMP, and if you try to initialise OpenMP twice (probably two different versions) in one process then everything goes to hell:&lt;/p&gt;
        &lt;p&gt;&lt;em&gt;OMP: Error #15: Initializing libomp.dylib, but found libomp.dylib already initialized.
        OMP: Hint This means that multiple copies of the OpenMP runtime have been linked into the program. That is dangerous, since it can degrade performance or cause incorrect results. The best thing to do is to ensure that only a single OpenMP runtime is linked into the process, e.g. by avoiding static linking of the OpenMP runtime in any library. As an unsafe, unsupported, undocumented workaround you can set the environment variable KMP_DUPLICATE_LIB_OK=TRUE to allow the program to continue to execute, but that may cause crashes or silently produce incorrect results. For more information, please see http://openmp.llvm.org&lt;/em&gt;&lt;/p&gt;
        &lt;p&gt;My solution was to adapt some simple &lt;a href=&quot;https://github.com/jhasse/ThreadPool/blob/master/ThreadPool.hpp&quot;&gt;thread pool implementation&lt;/a&gt; which directly manages C++11 std::threads, though this just feels a bit hacky to me.&lt;/p&gt;
        &lt;p&gt;Another trouble I had was just creating a matrix in C++ as these aren’t built-in. E.g. I would like to be able to write something like:&lt;/p&gt;
        &lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c--&quot; data-lang=&quot;c++&quot;&gt;&lt;span class=&quot;kt&quot;&gt;double&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matrix&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numRows&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numCols&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numRows&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numCols&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
        &lt;p&gt;This is impossible due to a design flaw in the C++ language, where this “[ ]” indexing can’t take two arguments.&lt;/p&gt;
        &lt;p&gt;Even having a data structure which just holds a pointer to matrix data, and stored the dimensions of the matrix, and provides ‘A(i, j)’ indexing is slightly a pain. I found that there’s proposal for future C++ versions to support an ‘mdspan’ for this case, and the Kokkos team has an &lt;a href=&quot;https://github.com/kokkos/mdspan&quot;&gt;reference implementation&lt;/a&gt; which I used. However this mdspan is a bit clunky, adds a lot of files which need to be compiled, and it makes any OpenACC versions of the code fail to compile with “[variableName] referenced in target region does not have a mappable type”.&lt;/p&gt;
        &lt;p&gt;It’d be ideal to have the plugin use a GPU if it is found to be attached, or to run using SIMD vector instructions on those CPUs which have this capability. However, if we compile a binary which has some fancy SIMD instructions and a user runs it on their older machine, we’ll crash both the plugin &amp;amp; Stata with an “illegal instruction” error. The only way around this which I can imagine is to JIT-compile the plugin after it is downloaded, though this sounds like it’d be a nightmare to implement…&lt;/p&gt;</content><author><name>pjl</name></author><category term="code" /><category term="math" /><summary type="html">Have you ever heard the line &quot;correlation does not equal causation&quot;? Well Empirical Dynamic Modeling (EDM) aims to fix that. I've been working on a plugin for Stata which implements EDM methods.</summary></entry><entry><title type="html">Rare event estimation 2.0</title><link href="https://pat-laub.github.io/2020/03/29/rare-events-updated.html" rel="alternate" type="text/html" title="Rare event estimation 2.0" /><published>2020-03-29T00:00:00+00:00</published><updated>2020-03-29T00:00:00+00:00</updated><id>https://pat-laub.github.io/2020/03/29/rare-events-updated</id><content type="html" xml:base="https://pat-laub.github.io/2020/03/29/rare-events-updated.html">&lt;p&gt;This animation is extracted from my updated rare-event estimation short course for masters students.
        It shows the progression of the Sequential Monte Carlo algorithm (for rare events). I’m quite happy with the &lt;a href=&quot;https://youtu.be/rnrAwAiBvqg&quot;&gt;&lt;strong&gt;video&lt;/strong&gt;&lt;/a&gt; I recorded to describe this algorithm, as I am with the &lt;a href=&quot;https://youtu.be/tuXXubOkFuY&quot;&gt;&lt;strong&gt;PyMC3 video&lt;/strong&gt;&lt;/a&gt; I made (recreating a fit for the COVID-19 incubation period distribution in PyMC3) and the final video on &lt;a href=&quot;https://youtu.be/KbarEA6Edoo&quot;&gt;&lt;strong&gt;high-performance Python&lt;/strong&gt;&lt;/a&gt; (profiling tools, vectorisation, Numba, just single-core improvements). All of the materials and code demonstration recordings for the course are on the &lt;a href=&quot;https://pat-laub.github.io/rare-events/&quot;&gt;&lt;strong&gt;course website&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;</content><author><name>pjl</name></author><category term="math" /><summary type="html">This animation is extracted from my updated rare-event estimation short course for masters students. It shows the progression of the Sequential Monte Carlo algorithm (for rare events). I’m quite happy with the video I recorded to describe this algorithm, as I am with the PyMC3 video I made (recreating a fit for the COVID-19 incubation period distribution in PyMC3) and the final video on high-performance Python (profiling tools, vectorisation, Numba, just single-core improvements). All of the materials and code demonstration recordings for the course are on the course website.</summary></entry><entry><title type="html">Research network plot</title><link href="https://pat-laub.github.io/2020/02/20/network-plot.html" rel="alternate" type="text/html" title="Research network plot" /><published>2020-02-20T00:00:00+00:00</published><updated>2020-02-20T00:00:00+00:00</updated><id>https://pat-laub.github.io/2020/02/20/network-plot</id><content type="html" xml:base="https://pat-laub.github.io/2020/02/20/network-plot.html">&lt;p&gt;Recently I made a visualization in Javascript to show the collaborations of the researchers in our lab here in Lyon. The plot shows each researcher as a node in the network, and edges are added to signify joint research papers between the (permanent) staff of the lab. The inner circles are coloured acccording to the field of research each person specialises in, and the outer circles show their membership in the many different research groups between our lab and external parties. New research groups which are about to start can be selected by the drop-down box.&lt;/p&gt;
        &lt;p&gt;The &lt;strong&gt;interactive version&lt;/strong&gt; is below. &lt;strong&gt;Try dragging a circle around&lt;/strong&gt; and watch the physics animation redraw the positions of the entire network (this is a bit easier with a real mouse than on a phone). Hover over a person see their name, or hover over an edge to see the number of joint papers.&lt;/p&gt;
        &lt;div id=&quot;network&quot;&gt;
        &lt;div class=&quot;vis-network&quot; tabindex=&quot;900&quot; style=&quot;position: relative; overflow: hidden; touch-action: pan-y; user-select: none; -webkit-user-drag: none; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); width: 100%; height: 100%;&quot;&gt;
        &lt;canvas style=&quot;position: relative; touch-action: none; user-select: none; -webkit-user-drag: none; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); width: 100%; height: 100%;&quot;&gt;
        &lt;/canvas&gt;
        &lt;div class=&quot;vis-manipulation&quot; style=&quot;display: none;&quot;&gt;&lt;/div&gt;&lt;div class=&quot;vis-edit-mode&quot; style=&quot;display: block;&quot;&gt;
        &lt;div class=&quot;vis-button vis-edit vis-edit-mode&quot; style=&quot;touch-action: pan-y; user-select: none; -webkit-user-drag: none; -webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt;
        &lt;div class=&quot;vis-label&quot;&gt;Edit&lt;/div&gt;
        &lt;/div&gt;
        &lt;/div&gt;
        &lt;div class=&quot;vis-close&quot; style=&quot;display: none;&quot;&gt;&lt;/div&gt;
        &lt;/div&gt;
        &lt;/div&gt;
        &lt;div&gt;
        &lt;br /&gt;
        &lt;p&gt;Select which new research group/s to draw:&lt;/p&gt;
        &lt;select id=&quot;newResearchGroup&quot; onchange=&quot;draw()&quot;&gt;
        &lt;option value=&quot;None&quot; selected=&quot;&quot;&gt;None&lt;/option&gt;
        &lt;option value=&quot;All&quot;&gt;All&lt;/option&gt;
        &lt;/select&gt;
        &lt;p&gt;Researcher's fields of interest:&lt;/p&gt;
        &lt;ul class=&quot;legend&quot;&gt;
        &lt;li&gt;&lt;span class=&quot;Economics&quot;&gt;&lt;/span&gt; Economics&lt;/li&gt;
        &lt;li&gt;&lt;span class=&quot;Management&quot;&gt;&lt;/span&gt; Management Sciences&lt;/li&gt;
        &lt;li&gt;&lt;span class=&quot;Applied&quot;&gt;&lt;/span&gt; Applied Mathematics&lt;/li&gt;
        &lt;li&gt;&lt;span class=&quot;Computer&quot;&gt;&lt;/span&gt; Computer Science&lt;/li&gt;
        &lt;/ul&gt;
        &lt;br /&gt;
        &lt;br /&gt;
        &lt;p&gt;Current research groups:&lt;/p&gt;
        &lt;ul class=&quot;legend&quot;&gt;
        &lt;li&gt;&lt;span class=&quot;Actuariat&quot;&gt;&lt;/span&gt; Actuariat Durable&lt;/li&gt;
        &lt;li&gt;&lt;span class=&quot;Chaire&quot;&gt;&lt;/span&gt; Chaire DAMI&lt;/li&gt;
        &lt;li&gt;&lt;span class=&quot;Lolita&quot;&gt;&lt;/span&gt; Lolita&lt;/li&gt;
        &lt;li&gt;&lt;span class=&quot;Prevent&quot;&gt;&lt;/span&gt; Prevent'Horizon&lt;/li&gt;
        &lt;li&gt;&lt;span class=&quot;Reference&quot;&gt;&lt;/span&gt; Reference Value&lt;/li&gt;
        &lt;/ul&gt;
        &lt;br /&gt;&lt;br /&gt;
        &lt;/div&gt;
        &lt;p&gt;It was quite gratifying to see it used in a real-world scenario (an external evaluation of the lab).&lt;/p&gt;
        &lt;p&gt;&lt;img src=&quot;/images/network_plot_in_meeting.jpg&quot; alt=&quot;image&quot; class=&quot;image post_image&quot; /&gt;&lt;/p&gt;
        &lt;p&gt;The &lt;a href=&quot;https://visjs.org/&quot;&gt;vis.js&lt;/a&gt; Javascript library is the main backbone of the code; &lt;a href=&quot;/assets/js/network_plot.js&quot;&gt;this is the javascript&lt;/a&gt; I wrote to use the vis.js library.&lt;/p&gt;</content><author><name>pjl</name></author><category term="code" /><summary type="html">Recently I made a visualization in Javascript to show the collaborations of the researchers in our lab here in Lyon. The plot shows each researcher as a node in the network, and edges are added to signify joint research papers between the (permanent) staff of the lab. Try dragging a circle around and watch the physics animation redraw the positions of the entire network in the interactive version.</summary></entry><entry><title type="html">Photos from 2019</title><link href="https://pat-laub.github.io/2020/01/01/photos-from-2019.html" rel="alternate" type="text/html" title="Photos from 2019" /><published>2020-01-01T00:00:00+00:00</published><updated>2020-01-01T00:00:00+00:00</updated><id>https://pat-laub.github.io/2020/01/01/photos-from-2019</id><content type="html" xml:base="https://pat-laub.github.io/2020/01/01/photos-from-2019.html">&lt;p&gt;&lt;a href=&quot;/portfolios/2019/&quot;&gt;&lt;strong&gt;Here are some of my favourite photos&lt;/strong&gt;&lt;/a&gt; from a great year in Lyon.&lt;/p&gt;</content><author><name>pjl</name></author><category term="photos" /><summary type="html">Here are some of my favourite photos from a great year in Lyon.</summary></entry><entry><title type="html">Rare event estimation</title><link href="https://pat-laub.github.io/2019/03/22/rare-events.html" rel="alternate" type="text/html" title="Rare event estimation" /><published>2019-03-22T00:00:00+00:00</published><updated>2019-03-22T00:00:00+00:00</updated><id>https://pat-laub.github.io/2019/03/22/rare-events</id><content type="html" xml:base="https://pat-laub.github.io/2019/03/22/rare-events.html">&lt;p&gt;The materials and lecture recordings for the course are on the &lt;a href=&quot;https://pat-laub.github.io/rare-events/2019/&quot;&gt;&lt;strong&gt;course website&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;</content><author><name>pjl</name></author><category term="math" /><summary type="html">The materials and lecture recordings for the course are on the course website.</summary></entry><entry><title type="html">Photos from 2018</title><link href="https://pat-laub.github.io/2019/01/01/photos-from-2018.html" rel="alternate" type="text/html" title="Photos from 2018" /><published>2019-01-01T00:00:00+00:00</published><updated>2019-01-01T00:00:00+00:00</updated><id>https://pat-laub.github.io/2019/01/01/photos-from-2018</id><content type="html" xml:base="https://pat-laub.github.io/2019/01/01/photos-from-2018.html">&lt;p&gt;Click &lt;a href=&quot;/portfolios/2018/&quot;&gt;&lt;strong&gt;here to see some of my favourite photos&lt;/strong&gt;&lt;/a&gt; which we took over the last crazy year.&lt;/p&gt;</content><author><name>pjl</name></author><category term="photos" /><summary type="html">Click here to see some of my favourite photos which we took over the last crazy year.</summary></entry><entry><title type="html">ISFA Seminar</title><link href="https://pat-laub.github.io/2018/11/16/isfa-seminar.html" rel="alternate" type="text/html" title="ISFA Seminar" /><published>2018-11-16T00:00:00+00:00</published><updated>2018-11-16T00:00:00+00:00</updated><id>https://pat-laub.github.io/2018/11/16/isfa-seminar</id><content type="html" xml:base="https://pat-laub.github.io/2018/11/16/isfa-seminar.html">&lt;p&gt;I gave a short talk on our recently accepted &lt;a href=&quot;https://www.mdpi.com/2227-9091/7/1/17&quot;&gt;&lt;strong&gt;paper&lt;/strong&gt;&lt;/a&gt;, titled “Phase-Type Models in Life Insurance: Fitting and Valuation of Equity-Linked Benefits.” A recording of it is on &lt;a href=&quot;https://youtu.be/8Ih2NxrLrmg&quot;&gt;&lt;strong&gt;Youtube&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;</content><author><name>pjl</name></author><category term="math" /><summary type="html">I gave a short talk on our recently accepted paper, titled “Phase-Type Models in Life Insurance: Fitting and Valuation of Equity-Linked Benefits.” A recording of it is on Youtube.</summary></entry><entry><title type="html">I have moved to Lyon</title><link href="https://pat-laub.github.io/2018/09/10/moved-to-lyon.html" rel="alternate" type="text/html" title="I have moved to Lyon" /><published>2018-09-10T00:00:00+00:00</published><updated>2018-09-10T00:00:00+00:00</updated><id>https://pat-laub.github.io/2018/09/10/moved-to-lyon</id><content type="html" xml:base="https://pat-laub.github.io/2018/09/10/moved-to-lyon.html">&lt;p&gt;I have started a post-doctoral position at the &lt;a href=&quot;http://chaire-dami.fr/en/&quot;&gt;&lt;strong&gt;Chair for Data Analytics &amp;amp; Models for Insurance&lt;/strong&gt;&lt;/a&gt; (Chaire-DAMI), which is associated with the &lt;a href=&quot;https://isfa.univ-lyon1.fr/&quot;&gt;&lt;strong&gt;Institut de Science Financière et d’Assurances&lt;/strong&gt;&lt;/a&gt; (ISFA) at the &lt;a href=&quot;https://www.univ-lyon1.fr/en/&quot;&gt;&lt;strong&gt;Université Claude Bernard Lyon 1&lt;/strong&gt;&lt;/a&gt; in Lyon, France.&lt;/p&gt;
        &lt;p&gt;My job is to research advanced analytics and machine learning algorithms for actuarial sciences and insurance, in particular, for improving risk-based pricing, and for developing predictive analytics.&lt;/p&gt;
        &lt;p&gt;I’m looking forward to spending two years in this beautiful city!&lt;/p&gt;</content><author><name>pjl</name></author><category term="photos" /><summary type="html">I have started a post-doctoral position at the Chair for Data Analytics &amp;amp; Models for Insurance (Chaire-DAMI), which is associated with the Institut de Science Financière et d’Assurances (ISFA) at the Université Claude Bernard Lyon 1 in Lyon, France.</summary></entry></feed>